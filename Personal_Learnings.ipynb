{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Customer loans in Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file serves as a tool for myself to revisit what I have done and the things that I have learnt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 1-2: Initialise & run a class to extract the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Initialise the class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Created a Python file to contain code for extraction - **db_utils.py**\n",
    "- Created a Class **RDSDatabase** which will be used for the extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Store Database Credentials**\n",
    "\n",
    "- Created a credentials.yaml file to store the database credentials provided by AiCore\n",
    "- Created a .gitignore file to keep the credentials secure and prevent them from being pushed to GitHub: \n",
    "\n",
    "    1. Create .gitignore file\n",
    "        - git init > git touch .gitignore > git nano .gitignore > \n",
    "    2. Add in credentials.yaml\n",
    "        - git add .gitignore \n",
    "    3. Commit to Github\n",
    "        - git commit -m \"Adding .gitignore to GitHub\" > git push origin main\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Load credentials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def load_credentials(filepath: str) -> dict:\n",
    "    with open(filepath, \"r\") as f:\n",
    "        credentials = yaml.safe_load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in ErrorHandling controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def load_credentials(filepath: str) -> dict:\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            credentials = yaml.safe_load(f)\n",
    "            return credentials\n",
    "    except ExceptionError as e:\n",
    "        print(f\"Error loading credentials {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Initialise RDSDatabase Connector**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initilising RDSDataseConnector taking the dictionary of credentials from above as a parameter\n",
    "- Setting \"*self.engine = None*\". Initilising it this way means that I am ensuring that the attributed are used only when they have valid values. It will be then set to a SQLAlchelmy engine object later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDSDatabaseConnector:\n",
    "    def __init__(self, credentials: dict):\n",
    "        self.credentials = credentials\n",
    "        self.engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Initialise SQLAlchemy Engine**\n",
    "\n",
    "- Defined method in RDSDatabaseConnector to set the engine to the SQLAlchemy Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def initialise_engine(self):\n",
    "        '''\n",
    "        Initialises a SQLAlchemy engine using the provided credentials\n",
    "        '''\n",
    "        try:\n",
    "            engine_url = (f\"postgresql://\n",
    "            {self.credentials['RDS_USER']}:{self.credentials['RDS_PASSWORD']}@{self.credentials['RDS_HOST']}/{self.credentials['RDS_DATABASE']}\")\n",
    "            self.engine=create_engine(engine_url)\n",
    "            print(\"SQLAlchemy engine initialized successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing SQLAlchemy engine: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Extract data**\n",
    "- Created a method to extract data from the RDS Database and return it as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(self, query:str) -> pd.DataFrame:\n",
    "    if self.engine is None: \n",
    "        raise ValueError (\"Engine is not initialised. Call initialise_engine() first\")\n",
    "    return pd.read_sql(query,self.engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Create function to save the extracted data to a local file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv (self, data: pd.DataFrame, filename: str):\n",
    "    data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Disconnect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disconnect():\n",
    "    if self.engine:\n",
    "        self.engine.dispose()\n",
    "        print(\"SQLAlchemy engine connection is closed\")\n",
    "    else:\n",
    "        print(\"No active connection to close.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Call the method** \n",
    "- To ensure that this code is only run when called upon I included the line if __name__ = \"__main__\" \n",
    "- Then called the method to connect to the database and disconnect once finished saving the data to the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    credentials = load_credentials(\"credentials.yaml\")\n",
    "\n",
    "    connector = RDSDatabaseConnector(credentials)\n",
    "    connector.initialise_engine()\n",
    "    \n",
    "    query = \"SELECT * FROM loan_payments\"\n",
    "    data = connector.extract_data(query)\n",
    "\n",
    "    if not data.empty:\n",
    "        connector.save_to_csv(data,\"loan_payments.csv\")\n",
    "    \n",
    "    connector.disconnect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This milestone is set to gain a deeper understanding of the data and identify any patterns which might exist. I'll be: \n",
    "- Reviewing the data to identify any issues, such as missing or incorrectly formatted data. \n",
    "- Applying statistical techniques to gain insight on the data's distribution and apply visualisation techniques to identify patterns or trends in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert columns to the correct format within DataTransform Class** \n",
    "\n",
    "Are there any columns in the exisiting df that need amending? \n",
    "\n",
    "From the original data *df = pd.df = pd.read_csv(\"loan_payments.csv) > print(df.types)* I convert the following: \n",
    "- **term** = currently an object so convert to numberical but converting to an integer representing the number of months.\n",
    "- **issue_date, earliest_credit_line, last_payment_date, next_payment_date, last_credit_pull_date** = need to convert to datetime.\n",
    "- **employment_length** = convert to an integer, for <1 and 10+ change to 0 and 10 respectively. \n",
    "- **loan_status** = As it contains a limited number of unique values I convert to category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For employment date I need to extract the number from the full details given in the column :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[column] = df[column].str.replace('< 1 year', '0')\n",
    "df[column] = df[column].str.replace('10+ years', '10')\n",
    "df[column] = df[column].str.extract(r'(\\d+)') #Explaination below\n",
    "df[column] = df[column].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For df[column].str.extract(r'(\\d+)')\n",
    "- **r** indicates that the string is a raw string, which means that the backslashes are treated as literal characters and not as escape characters\n",
    "- **\\d** matches any 0-9 digit\n",
    "- **+** means \"one or more\" of the preceeding element in this case is digits\n",
    "\n",
    "So **(r'(\\d+)')** matches one or more digits in the string and captures them as a group. The **str.extract** method returns a df with the extracted digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defined DataTransform Class and opened new ipynb to ensure all analysis is in one place**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This .ipynb is still used for my own personal understanding of what I learnt throughtout this project.\n",
    "\n",
    "- Analysis though is now found on loan_portfolio_analysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those columns that needed changing to datetime, if no date_format is provided, the method uses the default parsing behaviour of pd.to_datetime(). \n",
    "\n",
    "By explicitly stating the date format that we want to use we avoid potential errors that may arise later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def convert_to_datetime(self, column: str, date_format: str = None) -> pd.DataFrame:\n",
    "        if date_format:\n",
    "            self.df[column] = pd.to_datetime(self.df[column], format=date_format)\n",
    "        else: \n",
    "            self.df[column] = pd.to_datetime(self.df[column])\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the method we have to specify the format wanted. In the data these columns are presented by 'Jan-2021 or May-2025' etc so abbreviated month name and total year. \n",
    "\n",
    "In Python to format this you have many options: \n",
    "- %B = Full month name \n",
    "- %b = abbreviated month name\n",
    "- %Y = four-digit year\n",
    "- %y = two-digit year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multiple columns to be tranformed you can do all in one go via: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def convert_multiple_to_datetime(self, columns: list, date_format: str = None) -> pd.DataFrame:\n",
    "        for column in columns: \n",
    "            if date_format:\n",
    "                self.df[column] = pd.to_datetime(self.df[column], format=date_format)\n",
    "            else: \n",
    "                self.df[column] = pd.to_datetime(self.df[column])\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you call it with which will enable all the columns called out will be converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert_to_datetime = [\n",
    "    'issue_date',\n",
    "    'earliest_credit_line',\n",
    "    'last_payment_date',\n",
    "    'next_payment_date',\n",
    "    'last_credit_pull_date'\n",
    "]\n",
    "transformer.convert_multiple_to_datetime(\n",
    "    columns_to_convert_to_datetime, date_format='%b-%Y'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 2**\n",
    "\n",
    "- Describe all columns in the DataFrame to check their data types\n",
    "- Extract statistical values: median, standard deviation and mean from the columns and the DataFrame\n",
    "- Count distinct values in categorical columns\n",
    "- Print out the shape of the DataFrame\n",
    "- Generate a count/percentage count of NULL values in each column\n",
    "- Any other methods you may find useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I set up a new .py file **dataframe_info.py** to do host this code. It is best practice to seperate classes to ensure ease of following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
